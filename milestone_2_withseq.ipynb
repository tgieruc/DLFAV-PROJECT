{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(''), \"YOLOX\"))\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "from tracker import Tracker\n",
    "from pose_detector import PoseDetector\n",
    "from sequence_detector import SequenceDetector\n",
    "from pose_tracker import PoseTracker\n",
    "from visualizer import Visualizer\n",
    "from project_utils import identify_bbox\n",
    "\n",
    "environment = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if environment == \"colab\":\n",
    "    from IPython.display import display, Javascript, Image, clear_output\n",
    "    from base64 import b64decode, b64encode\n",
    "    import cv2, PIL, io\n",
    "     # Import PyDrive and associated libraries.\n",
    "    # This only needs to be done once per notebook.\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "\n",
    "    # Authenticate and create the PyDrive client.\n",
    "    # This only needs to be done once per notebook.\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    !gdown --id 1iYxlkO_RZJ_6iL6wdIbfjl8VprLlFp1c\n",
    "\n",
    "         # function to convert the JavaScript object into an OpenCV image\n",
    "    def js_to_image(js_reply):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "                js_reply: JavaScript object containing image from webcam\n",
    "        Returns:\n",
    "                img: OpenCV BGR image\n",
    "        \"\"\"\n",
    "        # decode base64 image\n",
    "        image_bytes = b64decode(js_reply.split(',')[1])\n",
    "        # convert bytes to numpy array\n",
    "        jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "        # decode numpy array into OpenCV BGR image\n",
    "        img = cv2.imdecode(jpg_as_np, flags=1)\n",
    "\n",
    "        return img\n",
    "\n",
    "    # function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
    "    def bbox_to_bytes(bbox_array):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "                bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
    "        Returns:\n",
    "              bytes: Base64 image byte string\n",
    "        \"\"\"\n",
    "        # convert array into PIL image\n",
    "        bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
    "        iobuf = io.BytesIO()\n",
    "        # format bbox into png for return\n",
    "        bbox_PIL.save(iobuf, format='png')\n",
    "        # format return string\n",
    "        bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
    "\n",
    "        return bbox_bytes\n",
    "else:\n",
    "    cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pose_tracker import PoseTracker\n",
    "tracker = Tracker('person')\n",
    "pose_detector = PoseDetector(n_feature=8, n_output=3, checkpoint_path=\"pose_classification_simplified.ckpt\", simple_mode=True, model_based=False)\n",
    "sequence_detector = SequenceDetector([1,2], 10)\n",
    "pose_tracker = PoseTracker(pose_detector, sequence_detector, tracker)\n",
    "visualizer = Visualizer(environment)\n",
    "poi = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agath\\anaconda3\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, Tracer, AutocastCPU, Autocast, Batched, VmapMode, Functionalize].\n\nCPU: registered at C:\\Users\\circleci\\project\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nQuantizedCPU: registered at C:\\Users\\circleci\\project\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:125 [kernel]\nBackendSelect: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradLazy: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:55 [backend fallback]\nAutogradXPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradMLC: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradHPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:68 [backend fallback]\nTracer: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\TraceTypeManual.cpp:293 [backend fallback]\nAutocastCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:461 [backend fallback]\nAutocast: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:305 [backend fallback]\nBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\BatchingRegistrations.cpp:1059 [backend fallback]\nVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:52 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3484/836841255.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m#bbox, pose = pose_detector.inference(im)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpose_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mvisualizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DLAV\\DLFAV-PROJECT\\pose_tracker.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, im)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Tracker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m# Filter out IDs that are not in both tracker and pose detectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DLAV\\DLFAV-PROJECT\\tracker.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'box_nums'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DLAV\\DLFAV-PROJECT\\detector.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, raw_img, visual, conf)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         outputs = postprocess(\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_conf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnmsthre\u001b[0m  \u001b[1;31m# TODO:用户可更改\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         )[0]\n",
      "\u001b[1;32m~\\Desktop\\DLAV\\DLFAV-PROJECT\\YOLOX\\yolox\\utils\\boxes.py\u001b[0m in \u001b[0;36mpostprocess\u001b[1;34m(prediction, num_classes, conf_thre, nms_thre)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         nms_out_index = torchvision.ops.batched_nms(\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mdetections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mdetections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdetections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\ops\\boxes.py\u001b[0m in \u001b[0;36mbatched_nms\u001b[1;34m(boxes, scores, idxs, iou_threshold)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_batched_nms_vanilla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_batched_nms_coordinate_trick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m             \u001b[1;31m# Not tracing, don't do anything\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[0mcompiled_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__original_fn\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\ops\\boxes.py\u001b[0m in \u001b[0;36m_batched_nms_coordinate_trick\u001b[1;34m(boxes, scores, idxs, iou_threshold)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0moffsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_coordinate\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mboxes_for_nms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboxes\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mkeep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes_for_nms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\ops\\boxes.py\u001b[0m in \u001b[0;36mnms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0m_assert_has_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, Tracer, AutocastCPU, Autocast, Batched, VmapMode, Functionalize].\n\nCPU: registered at C:\\Users\\circleci\\project\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nQuantizedCPU: registered at C:\\Users\\circleci\\project\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:125 [kernel]\nBackendSelect: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:35 [backend fallback]\nAutogradCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:39 [backend fallback]\nAutogradCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:47 [backend fallback]\nAutogradXLA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:51 [backend fallback]\nAutogradLazy: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:55 [backend fallback]\nAutogradXPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:43 [backend fallback]\nAutogradMLC: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:59 [backend fallback]\nAutogradHPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:68 [backend fallback]\nTracer: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\TraceTypeManual.cpp:293 [backend fallback]\nAutocastCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:461 [backend fallback]\nAutocast: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:305 [backend fallback]\nBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\BatchingRegistrations.cpp:1059 [backend fallback]\nVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:52 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "if environment == \"colab\":\n",
    "    # start streaming video from webcam\n",
    "    video_stream()\n",
    "    # label for video\n",
    "    label_html = 'Capturing...'\n",
    "    # initialze bounding box to empty\n",
    "    bbox = ''\n",
    "    #count = 0\n",
    "while True:\n",
    "    if environment == \"colab\":\n",
    "        js_reply = video_frame(label_html, bbox)\n",
    "        if not js_reply:\n",
    "            break\n",
    "        # convert JS response to OpenCV Image\n",
    "        img = js_to_image(js_reply[\"img\"])\n",
    "        # create transparent overlay for bounding box\n",
    "        bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
    "    else:\n",
    "        _, img = cap.read()\n",
    "        if img is None:\n",
    "            break\n",
    "\n",
    "    poi = None\n",
    "    im = imutils.resize(img, height=500)\n",
    "    #bbox, pose = pose_detector.inference(im)\n",
    "    outputs, poi = pose_tracker.update(im)\n",
    "    visualizer.show(im, outputs, poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
